pipenv installation error:
[format: pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org <package_name>]
pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org mcp-agent mcp-proxy

tracking command:
pipenv shell python -m 
python -m pipenv shell


remove virtual env:
pipenv --rm


[orion-ai]
Pre: pip install -r reqs.txt

[TERMINALS]

1. Start ollama instance (global)
a) set OLLAMA_HOST=0.0.0.0:11434 && ollama serve
b) ollama run llama3.2

2. Launch MCP server
a)  pipenv shell python -m
    cd mcp-github
    uvicorn main:app --reload --port 8081

3. Run app:
a) streamlit run app.py



-- ARCHIVED --
podman run -i --rm --env-file .env ghcr.io/github/github-mcp-server
[WORKING - IN ADMIN PS]
mcp-proxy --sse-port 8081 -- podman run -i --rm --env-file .env ghcr.io/github/github-mcp-server

4. expose mcp server + run
mcp-proxy --sse-port 8080 -- \
  podman run -i --rm --env-file .env ghcr.io/github/github-mcp-server

[MCP extension]
Add more MCP methods (run, list_files)
Add file type filtering or AST parsing
Replace Ollama with OpenAI, Mistral, or Claude via API


supabase:
react123@@

[REACT]
frontend: npm run dev
backend: node index.js


[TCP alternative]
cports: https://www.nirsoft.net/utils/cports.html
Resmon:
1. Press Win + R → type resmon → enter.
2. Go to Network tab → Listening Ports.

[Todo]
- framework parameters:
- using .gitignore
- allow user to specify langugau

- prompt chaining

- prompt library:
- dynamic variables > example: Act as a {language} software engineer

- prompt structure:
- write down step by step process of identifying use case (human)
- this will guide prompting structure

[crewai-examples repo]
pip install --upgrade crewai langchain
